## 数据探索
分桶（连续型数据离散化）
转化（非正态分布转正态分布）

## 数据清洗
异常值处理
缺失值处理

## 特征重要性分析（特征筛选）
- 为什么特征重要性分析很重要?
	- 如果有一个包含数十个甚至数百个特征的数据集，每个特征都可能对你的机器学习模型的性能有所贡献。但是并不是所有的特征都是一样的。有些可能是冗余的或不相关的，这会增加建模的复杂性并可能导致过拟合。
	- 特征重要性分析可以识别并关注最具信息量的特征，从而带来以下几个优势:
		- 改进的模型性能
		- 减少过度拟合
		- 更快的训练和推理
		- 增强的可解释性

- 特征重要性分析方法
	- 排列重要性 PermutationImportance
		- 该方法会随机排列每个特征的值，然后监控模型性能下降的程度。如果获得了更大的下降意味着特征更重要


- 为什么不同的方法会检测到不同的特征?
	- 他们用不同的方式衡量重要性:
		- 有的使用不同特特征进行预测，监控精度下降
		- 像XGBOOST或者回国模型使用内置重要性来进行特征的重要性排列
		- 而PCA着眼于方差解释
	- 不同模型有不同模型的方法：
		- 线性模型倾向于线性关系、树模型倾向于接近根的特征
	- 交互作用:
		- 有的方法可以获取特征之间的相互左右，而有一些则不行，这就会导致结果的差异
	- 不稳定:
		- 使用不同的数据子集，重要性值可能在同一方法的不同运行中有所不同，这是因为数据差异决定的
	- Hyperparameters:
		- 通过调整超参数，如PCA组件或树深度，也会影响结果
		- 所以不同的假设、偏差、数据处理和方法的可变性意味着它们并不总是在最重要的特征上保持一致。
		
- 选择特征重要性分析方法的一些最佳实践
	- 尝试多种方法以获得更健壮的视图
	- 聚合结果的集成方法
	- 更多地关注相对顺序，而不是绝对值
	- 差异并不一定意味着有问题，检查差异的原因会对数据和模型有更深入的了解


## 数据类型和特征编码方式
- 类别型数据=品质数据=定性数据
	- 分类型（分类型变量：如性别，取值只有男、女）——独热编码（One-Hot Encoding）
	- 顺序型（顺序型变量：如成绩等级，取值分为优良中差）——顺序编码（Ordinal Encoding）


- 数值型数据=数量数据=定量数据
	- 离散型（离散型数值变量：如车流量）——min-max标准化（Min-Max Normalization）
	- 连续型（连续型数值变量：如气温）——Z-score标准化