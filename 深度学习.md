# 神经网络分类
- 人工神经网络（ANN）
	- 前馈神经网络（Feedforward NN）
		- 单层神经网络
		- 两层神经网络
		- 多层神经网络（DNN）
			- 全连接神经网络
			- 深度信念网络DBN
			- 卷积神经网络CNN
	- 反馈神经网络
		- 循环神经网络RNN
		- Hopfiled神经网络
	- 图网络
- 生物神经网络（BNN）

- 前馈：描述的是网络的结构，指的是网络的信息流是单向的，不会构成环路。在此种神经网络中，各神经元从输入层开始，接收前一级输入，并输出到下一级，直至输出层。整个网络中无反馈，可用一个有向无环图表示。前馈神经网络采用一种单向多层结构，其中每一层包含若干个神经元，同一层的神经元之间没有互相连接，层间信息的传送只沿一个方向进行。
- 人工神经网络（ANN）、前馈神经网络和BP神经网络的关系
	- 人工神经网络包括前馈神经网络，BP神经网络属于前馈神经网络的一种，在前馈神经网络的基础上应用了BP算法用来优化参数以学习并接近真实值。
## 1、感知机（perceptron）


## 2、多层感知机（FNN）
- 全连接神经网络
	- 前向传播
	-  反向传播

## 3、深度神经网络（DNN）
隐含层大于3层

## 4、卷积神经网络（CNN）
局部连接神经网络（局部信息感知，在更高层进行综合）

- 局部卷积
- 参数共享
- 多卷积核
- 池化处理
- 多层处理

## 5、循环神经网络（RNN，Recurrent Neural Network）
隐含层的节点之间有连接，是主要用于对**序列结构的信息**进行分类、预测、处理的神经网络

![](./pic/p18.jpg)

- 序列结构的信息
	- 人类的自然语言，是不是符合某个逻辑或规则的字词拼凑排列起来的，这就是符合序列特性。
	- 语音，我们发出的声音，每一帧每一帧的衔接起来，才凑成了我们听到的话，这也具有序列特性
	- 视频，
	- 股票，随着时间的推移，会产生具有顺序的一系列数字，这些数字也是具有序列特性。
- 词特征向量
	- One-Hot 编码：将每个词表示为一个由 0 和 1 组成的向量，向量的长度等于词汇表的大小。向量中只有一个位置为 1，表示该词在词汇表中的位置。
	- 词频（Term Frequency）：将每个词表示为一个向量，向量的每个维度表示该词在文本中出现的频率。
	- 词袋模型（Bag-of-Words）：将每个词表示为一个向量，向量的每个维度表示该词在文本中的存在与否（例如，0 表示不存在，1 表示存在）。
	- TF-IDF（Term Frequency-Inverse Document Frequency）：将每个词表示为一个向量，向量的每个维度表示该词在文本中的 TF-IDF 值，用于衡量该词在文本中的重要性。
	- Word2Vec：将词表示为一个低维度的实数向量，向量的每个维度表示词在语义空间中的位置，具有一定的语义关联性。
- 长短时记忆网络（LSTM）----有门控装置：来控制每一时刻信息记忆和遗忘
- 双向循环神经网络
- 注意力机制
- transfromer


## 6、递归神经网络（RNN，Recursive Neural Network）
递归神经网络通常是指结构递归神经网络，在空间维度展开，**处理的是树状结构的信息**

## 7、生成式神经网络
- 自动编码器（编码器+解码器）--------降维、压缩
- VAE（变分自编码器）
	- 变分自编码器便是用“取值的概率分布”代替原先的单值来描述对特征的观察的模型

![](./pic/p19.png)
![](./pic/p20.jpg)
![](./pic/p21.jpg)

- GAN（生成对抗网络）


# 模型部署
### 部署、扩展、管理一个能够提供预测能力的 REST API
- Keras+Redis+Flask + Apache 

![](./pic/p17.jpg)


- Keras+Flask+Docker+Kubernetes

### 流水线模型部署
- 深度学习框架-中间表示-推理引擎
	- PyTorch - ONNX - ONNX Runtime（把 PyTorch 编写的模型转换成 ONNX 模型，用 ONNX Runtime 运行模型，完成模型部署）


# Tensorflow
TensorFlow会将所有的步骤事先生成计算图graph，可以理解为流水线，然后在session中根据定义好的流水线逐步进行计算。特征x和样本真实值y通过占位符事先定义，能够更灵活地接收各维度数据的输入，所有的权重和偏置等需要求解的参数通过TensorFlow的variable定义，全部变量和网络定义好之后，通过session启动训练，并输出结果。


## 梯度消失与梯度爆炸


## 神经网络优化
- 学习率
- 激活函数
- 损失函数
- 过拟合与欠拟合
- 优化器


## GPU
- 显卡（电脑进行数模信号转换的设备）
- GPU（显卡上的一块芯片）
- CUDA（构筑在显卡驱动之上的工具库（toolkit），CUDA是NVIDIA推出的用于自家GPU的并行计算框架，也就是说CUDA只能在NVIDIA的GPU上运行）
- cudnn（构筑在cuda之上的深度学习相关的工具库，使GPU进行深度神经网络的工作）
- pytorch/tensorflow（python深度学习相关的工具库）

利用Pytorch等深度学习框架编写代码，然后深度学习框架依赖cuDNN深度神经网络库，利用CUDA并行计算平台，实现深度学习代码在高性能GPU上的加速运行。