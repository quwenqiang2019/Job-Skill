# 深度学习


## 1、感知机（perceptron）


## 2、神经网络-多层感知机（FNN）
全连接神经网络

## 3、深度神经网络（DNN）
隐含层大于3层

## 4、卷积神经网络（CNN）
局部连接神经网络（局部信息感知，在更高层进行综合）

- 局部卷积
- 参数共享
- 多卷积核
- 池化处理
- 多层处理

## 5、循环神经网络（RNN，Recurrent Neural Network）
隐含层的节点之间有连接，是主要用于对**序列结构的信息**进行分类、预测、处理的神经网络

![](./pic/p18.jpg)

- 序列结构的信息
	- 人类的自然语言，是不是符合某个逻辑或规则的字词拼凑排列起来的，这就是符合序列特性。
	- 语音，我们发出的声音，每一帧每一帧的衔接起来，才凑成了我们听到的话，这也具有序列特性
	- 视频，
	- 股票，随着时间的推移，会产生具有顺序的一系列数字，这些数字也是具有序列特性。
- 词特征向量
	- One-Hot 编码：将每个词表示为一个由 0 和 1 组成的向量，向量的长度等于词汇表的大小。向量中只有一个位置为 1，表示该词在词汇表中的位置。
	- 词频（Term Frequency）：将每个词表示为一个向量，向量的每个维度表示该词在文本中出现的频率。
	- 词袋模型（Bag-of-Words）：将每个词表示为一个向量，向量的每个维度表示该词在文本中的存在与否（例如，0 表示不存在，1 表示存在）。
	- TF-IDF（Term Frequency-Inverse Document Frequency）：将每个词表示为一个向量，向量的每个维度表示该词在文本中的 TF-IDF 值，用于衡量该词在文本中的重要性。
	- Word2Vec：将词表示为一个低维度的实数向量，向量的每个维度表示词在语义空间中的位置，具有一定的语义关联性。
- 长短时记忆网络（LSTM）----有门控装置：来控制每一时刻信息记忆和遗忘的
- 双向循环神经网络
- 注意力机制
- transfromer


## 6、递归神经网络（RNN，Recursive Neural Network）
递归神经网络通常是指结构递归神经网络，在空间维度展开，**处理的是树状结构的信息**

## 7、生成式神经网络
- 自动编码器（编码器+解码器）--------降维、压缩
- VAE（变分自编码器）
	- 变分自编码器便是用“取值的概率分布”代替原先的单值来描述对特征的观察的模型

![](./pic/p19.png)
![](./pic/p20.jpg)
![](./pic/p21.jpg)

- GAN（生成对抗网络）


# 模型部署
### 部署、扩展、管理一个能够提供预测能力的 REST API
- Keras+Redis+Flask + Apache 

![](./pic/p17.jpg)


- Keras+Flask+Docker+Kubernetes

### 流水线模型部署
- 深度学习框架-中间表示-推理引擎
	- PyTorch - ONNX - ONNX Runtime（把 PyTorch 编写的模型转换成 ONNX 模型，用 ONNX Runtime 运行模型，完成模型部署）


# Tensorflow
TensorFlow会将所有的步骤事先生成计算图graph，可以理解为流水线，然后在session中根据定义好的流水线逐步进行计算。特征x和样本真实值y通过占位符事先定义，能够更灵活地接收各维度数据的输入，所有的权重和偏置等需要求解的参数通过TensorFlow的variable定义，全部变量和网络定义好之后，通过session启动训练，并输出结果。